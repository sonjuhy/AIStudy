{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/edint/64d115f7-57cc-417b-acf0-7738ac091615/Ivern/WorkSpace/CNN\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(\"..\")))\n",
    "print(os.path.abspath(os.path.join(\"..\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import tqdm\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class FER2013Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    FER2013 CSV 데이터셋\n",
    "    - columns: ['emotion', 'pixels', 'Usage']\n",
    "    - pixels: 공백으로 구분된 48x48 (그레이스케일)\n",
    "    - Usage: 'Training', 'PublicTest', 'PrivateTest'\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, csv_path, usage=\"Training\", transform=None):\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.data = self.data[self.data[\"Usage\"] == usage].reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        img = np.fromstring(row[\"pixels\"], dtype=np.uint8, sep=\" \").reshape(48, 48)\n",
    "\n",
    "        # 그레이스케일(1채널) → 3채널 복제 (MobileNet 호환)\n",
    "        img = np.repeat(img[..., np.newaxis], 3, axis=2)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = int(row[\"emotion\"])\n",
    "        return img, label\n",
    "\n",
    "\n",
    "def download_fer2013_dataset(\n",
    "    csv_path=\"./data/fer2013.csv\", batch_size=64, num_workers=4\n",
    "):\n",
    "    \"\"\"\n",
    "    FER2013 데이터셋 로드 함수\n",
    "    - FER2013 CSV 파일은 https://www.kaggle.com/datasets/deadskull7/fer2013 에서 다운로드 가능\n",
    "    \"\"\"\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(csv_path)\n",
    "        print(os.getcwd())\n",
    "        raise FileNotFoundError(\n",
    "            f\"'{csv_path}' not found. Please download fer2013.csv first.\"\n",
    "        )\n",
    "\n",
    "    # 이미지 전처리 정의\n",
    "    # transform_train = transforms.Compose(\n",
    "    #     [\n",
    "    #         transforms.ToPILImage(),\n",
    "    #         transforms.Resize(224),\n",
    "    #         transforms.RandomHorizontalFlip(),\n",
    "    #         transforms.ToTensor(),\n",
    "    #         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    #     ]\n",
    "    # )\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "    ])\n",
    "\n",
    "\n",
    "    transform_test = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # FER2013 CSV 분할 로드\n",
    "    trainset = FER2013Dataset(csv_path, usage=\"Training\", transform=transform_train)\n",
    "    valset = FER2013Dataset(csv_path, usage=\"PublicTest\", transform=transform_test)\n",
    "    testset = FER2013Dataset(csv_path, usage=\"PrivateTest\", transform=transform_test)\n",
    "\n",
    "    # 데이터로더 정의\n",
    "    trainloader = DataLoader(\n",
    "        trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers\n",
    "    )\n",
    "    valloader = DataLoader(\n",
    "        valset, batch_size=batch_size, shuffle=False, num_workers=num_workers\n",
    "    )\n",
    "    testloader = DataLoader(\n",
    "        testset, batch_size=batch_size, shuffle=False, num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Loaded FER2013 dataset: train={len(trainset)} val={len(valset)} test={len(testset)}\"\n",
    "    )\n",
    "\n",
    "    return {\"train\": trainloader, \"val\": valloader, \"test\": testloader}\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, mode=\"max\", min_delta=0.0):\n",
    "        self.patience = patience\n",
    "        self.mode = mode\n",
    "        self.min_delta = min_delta\n",
    "        self.best = None\n",
    "        self.num_bad = 0\n",
    "        self.should_stop = False\n",
    "\n",
    "    def step(self, current):\n",
    "        if self.best is None:\n",
    "            self.best = current\n",
    "            return False\n",
    "\n",
    "        improved = (current - self.best) > self.min_delta if self.mode == \"max\" else (self.best - current) > self.min_delta\n",
    "        if improved:\n",
    "            self.best = current\n",
    "            self.num_bad = 0\n",
    "        else:\n",
    "            self.num_bad += 1\n",
    "            if self.num_bad >= self.patience:\n",
    "                self.should_stop = True\n",
    "        return self.should_stop\n",
    "\n",
    "def compute_weights_from_csv(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    y = df[df[\"Usage\"] == \"Training\"][\"emotion\"].astype(int).values\n",
    "    classes = np.arange(7)\n",
    "    w = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y)\n",
    "    return torch.tensor(w, dtype=torch.float32)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device, criterion):\n",
    "    model.eval()\n",
    "    loss_sum, n = 0.0, 0\n",
    "    preds, gts = [], []\n",
    "    for x, y in loader:\n",
    "        x = x.to(device, non_blocking=True); y = y.to(device, non_blocking=True)\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss_sum += loss.item() * x.size(0); n += x.size(0)\n",
    "        preds.extend(logits.argmax(1).cpu().numpy())\n",
    "        gts.extend(y.cpu().numpy())\n",
    "    loss = loss_sum / max(1, n)\n",
    "    acc = accuracy_score(gts, preds)\n",
    "    f1m = f1_score(gts, preds, average=\"macro\")\n",
    "    return loss, acc, f1m, np.array(gts), np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded FER2013 dataset: train=28709 val=3589 test=3589\n"
     ]
    }
   ],
   "source": [
    "loader_dict = download_fer2013_dataset()\n",
    "train_loader = loader_dict[\"train\"]\n",
    "test_loader = loader_dict[\"test\"]\n",
    "val_loader = loader_dict['val']\n",
    "\n",
    "\n",
    "# FER-2013 클래스 이름\n",
    "classes = (\"angry\", \"disgust\", \"fear\", \"happy\", \"sad\", \"surprise\", \"neutral\")\n",
    "\n",
    "# 테스트셋에서 일부 샘플 가져오기\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device : cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_604609/3148298269.py:14: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(not \"store_true\") and device.type==\"cuda\")\n"
     ]
    }
   ],
   "source": [
    "from mobilenet.mobilenet_3 import MobileNetV3Large\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device : {device}\")\n",
    "model = MobileNetV3Large(num_classes=7).to(device)\n",
    "\n",
    "class_weights = compute_weights_from_csv(\"./data/fer2013.csv\").to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "# 검증 손실 기준으로 lr 감소\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=2)\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(not \"store_true\") and device.type==\"cuda\")\n",
    "early = EarlyStopping(patience=7, mode=\"max\", min_delta=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/100: 100%|██████████| 449/449 [00:27<00:00, 16.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[000] train_loss=0.9609 | val_loss=1.0471 | val_acc=0.6252 | val_f1=0.5843 | time=28.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 449/449 [00:27<00:00, 16.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001] train_loss=0.9425 | val_loss=1.0361 | val_acc=0.6311 | val_f1=0.5922 | time=28.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████| 449/449 [00:27<00:00, 16.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[002] train_loss=0.9228 | val_loss=1.0333 | val_acc=0.6311 | val_f1=0.5930 | time=29.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|██████████| 449/449 [00:27<00:00, 16.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[003] train_loss=0.9072 | val_loss=1.0174 | val_acc=0.6322 | val_f1=0.5966 | time=29.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|██████████| 449/449 [00:27<00:00, 16.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[004] train_loss=0.8892 | val_loss=1.0247 | val_acc=0.6397 | val_f1=0.6063 | time=29.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|██████████| 449/449 [00:27<00:00, 16.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[005] train_loss=0.8696 | val_loss=1.0207 | val_acc=0.6330 | val_f1=0.5980 | time=29.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|██████████| 449/449 [00:27<00:00, 16.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[006] train_loss=0.8581 | val_loss=1.0172 | val_acc=0.6422 | val_f1=0.6063 | time=29.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|██████████| 449/449 [00:27<00:00, 16.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[007] train_loss=0.8405 | val_loss=1.0125 | val_acc=0.6450 | val_f1=0.6074 | time=29.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|██████████| 449/449 [00:27<00:00, 16.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[008] train_loss=0.8315 | val_loss=1.0096 | val_acc=0.6495 | val_f1=0.6194 | time=29.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|██████████| 449/449 [00:27<00:00, 16.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[009] train_loss=0.8068 | val_loss=1.0160 | val_acc=0.6531 | val_f1=0.6284 | time=29.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|██████████| 449/449 [00:27<00:00, 16.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[010] train_loss=0.8044 | val_loss=1.0353 | val_acc=0.6509 | val_f1=0.6251 | time=29.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 449/449 [00:27<00:00, 16.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[011] train_loss=0.7937 | val_loss=1.0138 | val_acc=0.6445 | val_f1=0.6073 | time=29.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|██████████| 449/449 [00:27<00:00, 16.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[012] train_loss=0.7774 | val_loss=1.0200 | val_acc=0.6500 | val_f1=0.6176 | time=28.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|██████████| 449/449 [00:27<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[013] train_loss=0.7736 | val_loss=1.0348 | val_acc=0.6537 | val_f1=0.6218 | time=29.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|██████████| 449/449 [00:27<00:00, 16.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[014] train_loss=0.7669 | val_loss=1.0275 | val_acc=0.6545 | val_f1=0.6301 | time=29.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|██████████| 449/449 [00:27<00:00, 16.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[015] train_loss=0.7561 | val_loss=1.0306 | val_acc=0.6559 | val_f1=0.6282 | time=29.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|██████████| 449/449 [00:27<00:00, 16.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[016] train_loss=0.7589 | val_loss=1.0263 | val_acc=0.6542 | val_f1=0.6239 | time=29.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|██████████| 449/449 [00:27<00:00, 16.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[017] train_loss=0.7582 | val_loss=1.0321 | val_acc=0.6551 | val_f1=0.6274 | time=29.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: 100%|██████████| 449/449 [00:27<00:00, 16.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[018] train_loss=0.7488 | val_loss=1.0404 | val_acc=0.6562 | val_f1=0.6277 | time=29.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: 100%|██████████| 449/449 [00:27<00:00, 16.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[019] train_loss=0.7475 | val_loss=1.0361 | val_acc=0.6553 | val_f1=0.6288 | time=29.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: 100%|██████████| 449/449 [00:27<00:00, 16.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[020] train_loss=0.7357 | val_loss=1.0362 | val_acc=0.6584 | val_f1=0.6323 | time=29.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|██████████| 449/449 [00:27<00:00, 16.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[021] train_loss=0.7442 | val_loss=1.0365 | val_acc=0.6559 | val_f1=0.6285 | time=29.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|██████████| 449/449 [00:27<00:00, 16.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[022] train_loss=0.7440 | val_loss=1.0365 | val_acc=0.6567 | val_f1=0.6284 | time=29.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: 100%|██████████| 449/449 [00:27<00:00, 16.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[023] train_loss=0.7416 | val_loss=1.0340 | val_acc=0.6590 | val_f1=0.6325 | time=29.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100: 100%|██████████| 449/449 [00:27<00:00, 16.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[024] train_loss=0.7438 | val_loss=1.0389 | val_acc=0.6592 | val_f1=0.6320 | time=29.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100: 100%|██████████| 449/449 [00:27<00:00, 16.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[025] train_loss=0.7406 | val_loss=1.0408 | val_acc=0.6559 | val_f1=0.6290 | time=29.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100: 100%|██████████| 449/449 [00:27<00:00, 16.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[026] train_loss=0.7411 | val_loss=1.0422 | val_acc=0.6562 | val_f1=0.6304 | time=29.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100: 100%|██████████| 449/449 [00:27<00:00, 16.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[027] train_loss=0.7321 | val_loss=1.0397 | val_acc=0.6565 | val_f1=0.6313 | time=29.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100: 100%|██████████| 449/449 [00:27<00:00, 16.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[028] train_loss=0.7394 | val_loss=1.0429 | val_acc=0.6578 | val_f1=0.6289 | time=29.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100: 100%|██████████| 449/449 [00:27<00:00, 16.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[029] train_loss=0.7326 | val_loss=1.0453 | val_acc=0.6609 | val_f1=0.6324 | time=29.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100: 100%|██████████| 449/449 [00:27<00:00, 16.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[030] train_loss=0.7365 | val_loss=1.0444 | val_acc=0.6581 | val_f1=0.6328 | time=29.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|██████████| 449/449 [00:27<00:00, 16.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[031] train_loss=0.7407 | val_loss=1.0423 | val_acc=0.6576 | val_f1=0.6297 | time=29.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100: 100%|██████████| 449/449 [00:27<00:00, 16.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[032] train_loss=0.7392 | val_loss=1.0395 | val_acc=0.6567 | val_f1=0.6302 | time=29.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100: 100%|██████████| 449/449 [00:27<00:00, 16.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[033] train_loss=0.7418 | val_loss=1.0431 | val_acc=0.6609 | val_f1=0.6335 | time=29.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100: 100%|██████████| 449/449 [00:27<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[034] train_loss=0.7310 | val_loss=1.0477 | val_acc=0.6590 | val_f1=0.6329 | time=28.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100: 100%|██████████| 449/449 [00:27<00:00, 16.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[035] train_loss=0.7437 | val_loss=1.0360 | val_acc=0.6604 | val_f1=0.6311 | time=29.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100: 100%|██████████| 449/449 [00:27<00:00, 16.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[036] train_loss=0.7404 | val_loss=1.0416 | val_acc=0.6567 | val_f1=0.6308 | time=29.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100: 100%|██████████| 449/449 [00:27<00:00, 16.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[037] train_loss=0.7468 | val_loss=1.0448 | val_acc=0.6612 | val_f1=0.6342 | time=29.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100: 100%|██████████| 449/449 [00:27<00:00, 16.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[038] train_loss=0.7395 | val_loss=1.0422 | val_acc=0.6584 | val_f1=0.6332 | time=29.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100: 100%|██████████| 449/449 [00:27<00:00, 16.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[039] train_loss=0.7399 | val_loss=1.0420 | val_acc=0.6592 | val_f1=0.6319 | time=29.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100: 100%|██████████| 449/449 [00:27<00:00, 16.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[040] train_loss=0.7373 | val_loss=1.0428 | val_acc=0.6592 | val_f1=0.6333 | time=29.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100: 100%|██████████| 449/449 [00:27<00:00, 16.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[041] train_loss=0.7400 | val_loss=1.0370 | val_acc=0.6573 | val_f1=0.6304 | time=29.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100: 100%|██████████| 449/449 [00:27<00:00, 16.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[042] train_loss=0.7350 | val_loss=1.0422 | val_acc=0.6587 | val_f1=0.6315 | time=29.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/100: 100%|██████████| 449/449 [00:27<00:00, 16.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[043] train_loss=0.7385 | val_loss=1.0441 | val_acc=0.6559 | val_f1=0.6294 | time=29.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/100: 100%|██████████| 449/449 [00:27<00:00, 16.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[044] train_loss=0.7416 | val_loss=1.0380 | val_acc=0.6595 | val_f1=0.6314 | time=29.1s\n",
      "Early stopping at epoch 44 (best F1=0.6342 @ 37)\n",
      "Loaded BEST checkpoint from epoch 44\n",
      "[TEST] loss=2.7479 | acc=0.6367 | f1=0.6226\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry      0.548     0.542     0.545       491\n",
      "     disgust      0.800     0.509     0.622        55\n",
      "        fear      0.472     0.498     0.485       528\n",
      "       happy      0.856     0.862     0.859       879\n",
      "         sad      0.477     0.517     0.496       594\n",
      "    surprise      0.820     0.714     0.763       416\n",
      "     neutral      0.588     0.585     0.587       626\n",
      "\n",
      "    accuracy                          0.637      3589\n",
      "   macro avg      0.652     0.604     0.623      3589\n",
      "weighted avg      0.643     0.637     0.639      3589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Start Training...')\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "best_f1, best_epoch = -1, -1\n",
    "train_losses, val_losses = [], []\n",
    "train_accs, val_accs = [], []\n",
    "\n",
    "for epoch in range(epochs+1):\n",
    "    # ---- Training ----\n",
    "    model.train()\n",
    "    t0 = time.time()\n",
    "    run_loss, n = 0.0, 0\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    \n",
    "    for x, y in tqdm.tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs}\"):\n",
    "        x = x.to(device, non_blocking=True); y = y.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.amp.autocast(enabled=scaler.is_enabled(), device_type=\"cpu\"):\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "        if scaler.is_enabled():\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward(); optimizer.step()\n",
    "        run_loss += loss.item() * x.size(0); n += x.size(0)\n",
    "\n",
    "    train_loss = run_loss / max(1, n)\n",
    "    # ── Validation\n",
    "    val_loss, val_acc, val_f1, gts, preds = evaluate(model, val_loader, device, criterion)\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # 체크포인트\n",
    "    is_best = val_f1 > best_f1\n",
    "    if is_best:\n",
    "        best_f1, best_epoch = val_f1, epoch\n",
    "        torch.save({\"epoch\": epoch,\n",
    "                    \"state_dict\": model.state_dict(),\n",
    "                    \"best_val_f1\": best_f1},\n",
    "                    os.path.join(\"mobilenetv3_large_fer2013_best.pth\"))\n",
    "    torch.save({\"epoch\": epoch,\n",
    "                \"state_dict\": model.state_dict(),\n",
    "                \"best_val_f1\": best_f1},\n",
    "                os.path.join(\"mobilenetv3_large_fer2013_last.pth\"))\n",
    "\n",
    "    dt = time.time() - t0\n",
    "    print(f\"[{epoch:03d}] train_loss={train_loss:.4f} | val_loss={val_loss:.4f} \"\n",
    "            f\"| val_acc={val_acc:.4f} | val_f1={val_f1:.4f} | time={dt:.1f}s\")\n",
    "\n",
    "    # EarlyStopping (기준: val_f1 최대화)\n",
    "    if early.step(val_f1):\n",
    "        print(f\"Early stopping at epoch {epoch} (best F1={best_f1:.4f} @ {best_epoch})\")\n",
    "        break\n",
    "    \n",
    "    \n",
    "# ── Test (best 가중치 로드)\n",
    "best_path = os.path.join(\"mobilenetv3_large_fer2013.pth\")\n",
    "if os.path.exists(best_path):\n",
    "    ckpt = torch.load(best_path, map_location=\"cpu\")\n",
    "    # print(ckpt.keys())\n",
    "    # model.load_state_dict(torch.load(\"mobilenetv3_large_cifar10.pth\", map_location=device))\n",
    "    model.load_state_dict(ckpt)\n",
    "    print(f\"Loaded BEST checkpoint from epoch {epoch}\")\n",
    "\n",
    "test_loss, test_acc, test_f1, gts, preds = evaluate(model, test_loader, device, criterion)\n",
    "print(f\"[TEST] loss={test_loss:.4f} | acc={test_acc:.4f} | f1={test_f1:.4f}\")\n",
    "print(classification_report(gts, preds, target_names=classes, digits=3))\n",
    "\n",
    "    # torch.save(model.state_dict(), \"mobilenetv3_large_fer2013.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (100,) and (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Loss\u001b[39;00m\n\u001b[32m      6\u001b[39m plt.subplot(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_losses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mo-\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTrain Loss\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m plt.plot(\u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, epochs+\u001b[32m1\u001b[39m), val_losses, \u001b[33m'\u001b[39m\u001b[33ms--\u001b[39m\u001b[33m'\u001b[39m, label=\u001b[33m'\u001b[39m\u001b[33mVal Loss\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      9\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mLoss Trend\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Ivern/WorkSpace/CNN/venv/lib/python3.12/site-packages/matplotlib/pyplot.py:3838\u001b[39m, in \u001b[36mplot\u001b[39m\u001b[34m(scalex, scaley, data, *args, **kwargs)\u001b[39m\n\u001b[32m   3830\u001b[39m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes.plot)\n\u001b[32m   3831\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplot\u001b[39m(\n\u001b[32m   3832\u001b[39m     *args: \u001b[38;5;28mfloat\u001b[39m | ArrayLike | \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3836\u001b[39m     **kwargs,\n\u001b[32m   3837\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[32m-> \u001b[39m\u001b[32m3838\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3839\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3840\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscalex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3841\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscaley\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3842\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3843\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3844\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Ivern/WorkSpace/CNN/venv/lib/python3.12/site-packages/matplotlib/axes/_axes.py:1777\u001b[39m, in \u001b[36mAxes.plot\u001b[39m\u001b[34m(self, scalex, scaley, data, *args, **kwargs)\u001b[39m\n\u001b[32m   1534\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1535\u001b[39m \u001b[33;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[32m   1536\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1774\u001b[39m \u001b[33;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1776\u001b[39m kwargs = cbook.normalize_kwargs(kwargs, mlines.Line2D)\n\u001b[32m-> \u001b[39m\u001b[32m1777\u001b[39m lines = [*\u001b[38;5;28mself\u001b[39m._get_lines(\u001b[38;5;28mself\u001b[39m, *args, data=data, **kwargs)]\n\u001b[32m   1778\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[32m   1779\u001b[39m     \u001b[38;5;28mself\u001b[39m.add_line(line)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Ivern/WorkSpace/CNN/venv/lib/python3.12/site-packages/matplotlib/axes/_base.py:297\u001b[39m, in \u001b[36m_process_plot_var_args.__call__\u001b[39m\u001b[34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m    295\u001b[39m     this += args[\u001b[32m0\u001b[39m],\n\u001b[32m    296\u001b[39m     args = args[\u001b[32m1\u001b[39m:]\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_kwargs\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Ivern/WorkSpace/CNN/venv/lib/python3.12/site-packages/matplotlib/axes/_base.py:494\u001b[39m, in \u001b[36m_process_plot_var_args._plot_args\u001b[39m\u001b[34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[39m\n\u001b[32m    491\u001b[39m     axes.yaxis.update_units(y)\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x.shape[\u001b[32m0\u001b[39m] != y.shape[\u001b[32m0\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mx and y must have same first dimension, but \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    495\u001b[39m                      \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    496\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x.ndim > \u001b[32m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y.ndim > \u001b[32m2\u001b[39m:\n\u001b[32m    497\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mx and y can be no greater than 2D, but have \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    498\u001b[39m                      \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: x and y must have same first dimension, but have shapes (100,) and (0,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, epochs+1), train_losses, 'o-', label='Train Loss')\n",
    "plt.plot(range(1, epochs+1), val_losses, 's--', label='Val Loss')\n",
    "plt.title('Loss Trend')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, epochs+1), train_accs, 'o-', label='Train Accuracy')\n",
    "plt.plot(range(1, epochs+1), val_accs, 's--', label='Val Accuracy')\n",
    "plt.title('Accuracy Trend')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
